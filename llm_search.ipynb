{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "578dfd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import torch\n",
    "import accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os \n",
    "from mistralai import Mistral\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from vectordb import VectorDB\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7d759365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "11031bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MISTRAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ae1be96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Mistral(api_key=API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d9db4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"document_metadata.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8e66d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "USE_MISTRAL = True \n",
    "\n",
    "\n",
    "def query_to_filters(query: str, max_new_tokens: int = 150):\n",
    "    \"\"\"\n",
    "    Convert English or Arabic query about contracts into a structured filter dict:\n",
    "    { company, amount_min, amount_max, year_min, year_max, keywords }\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Convert this query about documents into a JSON object with keys:\n",
    "author, category, year_min, year_max, tags, keywords.\n",
    "Use null if not specified. Respond ONLY with valid JSON.\n",
    "- The 'keywords' field should always be in English (the language of the CSV),\n",
    "even if the input query is in Arabic.\n",
    "- If multiple tags are mentioned, return them as a list.\n",
    "- If a date range is mentioned, fill year_min and year_max.\n",
    "- If only a single year is mentioned, set both year_min and year_max to that year.\n",
    "- If a field is not mentioned, set it to null.\n",
    "\n",
    "English examples:\n",
    "\"Reports by John Smith\" => {{\"author\":\"John Smith\",\"category\":\"Report\",\"year_min\":null,\"year_max\":null,\"tags\":null,\"keywords\":null}}\n",
    "\"Documents about financial performance in 2023\" => {{\"author\":null,\"category\":null,\"year_min\":2023,\"year_max\":2023,\"tags\":null,\"keywords\":\"financial performance\"}}\n",
    "\"Policies by HR with tag onboarding between 2021 and 2022\" => {{\"author\":\"HR\",\"category\":\"Policy\",\"year_min\":2021,\"year_max\":2022,\"tags\":[\"onboarding\"],\"keywords\":null}}\n",
    "\"Documents tagged marketing and sales in 2023\" => {{\"author\":null,\"category\":null,\"year_min\":2023,\"year_max\":2023,\"tags\":[\"marketing\",\"sales\"],\"keywords\":null}}\n",
    "\n",
    "Arabic examples:\n",
    "\"تقارير من جون سميث\" => {{\"author\":\"John Smith\",\"category\":\"Report\",\"year_min\":null,\"year_max\":null,\"tags\":null,\"keywords\":null}}\n",
    "\"مستندات عن الأداء المالي في ٢٠٢٣\" => {{\"author\":null,\"category\":null,\"year_min\":2023,\"year_max\":2023,\"tags\":null,\"keywords\":\"financial performance\"}}\n",
    "\"سياسات من قسم الموارد البشرية مع علامات onboarding بين 2021 و 2022\" => {{\"author\":\"HR\",\"category\":\"Policy\",\"year_min\":2021,\"year_max\":2022,\"tags\":[\"onboarding\"],\"keywords\":null}}\n",
    "\"مستندات عن التسويق والمبيعات في 2023\" => {{\"author\":null,\"category\":null,\"year_min\":2023,\"year_max\":2023,\"tags\":[\"marketing\",\"sales\"],\"keywords\":null}}\n",
    "\n",
    "Query: \"{query}\"\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    if USE_MISTRAL:\n",
    "        response = client.chat.complete(\n",
    "            model=\"ministral-3b-latest\",  \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "        )\n",
    "        raw_output = response.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        start = raw_output.find(\"{\")\n",
    "        end = raw_output.rfind(\"}\") + 1\n",
    "        json_str = raw_output[start:end]\n",
    "        filters = json.loads(json_str)\n",
    "        \n",
    "        for key in [ \"document_id\",\"title\",\"author\",\"created_date\",\"last_modified\",\"category\",\"tags\",\"content\"]:\n",
    "            if key not in filters:\n",
    "                filters[key] = None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"!!! Fallback triggered: returning empty filters\")\n",
    "        print(\"Raw model response:\", raw_output)\n",
    "        filters = {\n",
    "            \"author\": None,\n",
    "            \"category\": None,\n",
    "            \"year_min\": None,\n",
    "            \"year_max\": None,\n",
    "            \"tags\": None,\n",
    "            \"keywords\": None\n",
    "        }\n",
    "\n",
    "    return filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3184def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "import re\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.replace(\"أ\", \"ا\").replace(\"إ\", \"ا\").replace(\"آ\", \"ا\").replace(\"ى\", \"ي\").strip()\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f814f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('msmarco-MiniLM-L6-cos-v5')\n",
    "model.save('models/msmarco-MiniLM-L6-cos-v5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_embeddings(df, embed_client):\n",
    "#     embeddings = []\n",
    "#     for i, row in df.iterrows():\n",
    "#         text = f\"{row['title']} {row['tags']} {row['content']}\"\n",
    "#         response = embed_client.embeddings.create(\n",
    "#             model=\"mistral-embed\",\n",
    "#             inputs=[text]\n",
    "#         )\n",
    "#         embeddings.append(response.data[0].embedding)\n",
    "#     df[\"embedding\"] = embeddings\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5dabfe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(df, model):\n",
    "    embeddings = []\n",
    "    for i, row in df.iterrows():\n",
    "        text = f\"{row['title']} {row['tags']} {row['content']}\"\n",
    "        emb = model.encode(text, convert_to_numpy=True)  \n",
    "        embeddings.append(emb)\n",
    "    \n",
    "    df[\"embedding\"] = embeddings\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ded839d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_embeddings(df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "117e89ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 384)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.array(df[\"embedding\"].to_list()).astype(\"float32\")\n",
    "\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3ba14ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdb = VectorDB(dim=df[\"embedding\"][0].__len__(),  \n",
    "               index_path=\"vector_index.faiss\",\n",
    "               meta_path=\"vector_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "37cd2537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorDB saved: vector_index.faiss + vector_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "vdb.build(df, embedding_col=\"embedding\")\n",
    "\n",
    "vdb.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "408eb6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, embed_client, df, index, top_k=5):\n",
    "    response = embed_client.embeddings.create(\n",
    "        model=\"mistral-embed\",\n",
    "        inputs=[query]\n",
    "    )\n",
    "    query_vec = np.array(response.data[0].embedding).astype(\"float32\").reshape(1, -1)\n",
    "\n",
    "    distances, indices = index.search(query_vec, top_k)\n",
    "\n",
    "    sims = 1 / (1 + distances[0])\n",
    "\n",
    "    results = df.iloc[indices[0]].copy()\n",
    "    results[\"similarity\"] = sims\n",
    "    \n",
    "    return results[[\"title\", \"author\", \"category\", \"tags\", \"similarity\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2242b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search_faiss(query, vdb, top_k=5):\n",
    "    query_vec = model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "    results = vdb.search(query_vec, top_k=top_k)\n",
    "    return results[[\"title\", \"author\", \"category\", \"tags\", \"similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6079ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_csv(query):\n",
    "    filters = query_to_filters(query)\n",
    "    print(\"Structured query:\", filters)\n",
    "\n",
    "    results = df.copy()\n",
    "\n",
    "    if filters.get(\"author\"):\n",
    "        results = results[results[\"author\"].str.contains(filters[\"author\"], case=False, na=False)]\n",
    "    if filters.get(\"category\"):\n",
    "        results = results[results[\"category\"].str.contains(filters[\"category\"], case=False, na=False)]\n",
    "    if filters.get(\"year_min\"):\n",
    "        results = results[pd.to_datetime(results[\"created_date\"]).dt.year >= filters[\"year_min\"]]\n",
    "    if filters.get(\"year_max\"):\n",
    "        results = results[pd.to_datetime(results[\"created_date\"]).dt.year <= filters[\"year_max\"]]\n",
    "    if filters.get(\"tags\"):\n",
    "        tag_pattern = \"|\".join(filters[\"tags\"])\n",
    "        results = results[results[\"tags\"].str.contains(tag_pattern, case=False, na=False)]\n",
    "    if filters.get(\"keywords\"):\n",
    "        keyword_text = filters[\"keywords\"].strip()\n",
    "        if keyword_text:\n",
    "            words = re.split(r\"\\s+\", keyword_text)\n",
    "            words_normalized = [normalize_arabic(w) for w in words]\n",
    "\n",
    "            results[\"content_normalized\"] = results[\"content\"].apply(normalize_arabic)\n",
    "\n",
    "            pattern = \"|\".join(re.escape(w) for w in words_normalized)\n",
    "            results = results[results[\"content_normalized\"].str.contains(pattern, case=False, regex=True)]\n",
    "\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b7d22711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search_gradio(query):\n",
    "    return semantic_search_faiss(query, vdb=vdb, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc5b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as iface:\n",
    "    gr.Markdown(\"# Arabic Contract Search\")\n",
    "    gr.Markdown(\"Choose structured or semantic search\")\n",
    "    \n",
    "    with gr.Tab(\"Structured Search\"):\n",
    "        query_input = gr.Textbox(label=\"Enter your Arabic query\")\n",
    "        output_table = gr.Dataframe(label=\"Results\")\n",
    "        search_btn = gr.Button(\"Search (Structured)\")\n",
    "        search_btn.click(search_csv, inputs=query_input, outputs=output_table)\n",
    "\n",
    "    with gr.Tab(\"Semantic Search\"):\n",
    "        sem_query_input = gr.Textbox(label=\"Enter your query for semantic search\")\n",
    "        sem_output_table = gr.Dataframe(label=\"Results\")\n",
    "        sem_search_btn = gr.Button(\"Search (Semantic)\")\n",
    "\n",
    "        sem_search_btn.click(semantic_search_gradio, inputs=sem_query_input, outputs=sem_output_table)\n",
    "\n",
    "\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
